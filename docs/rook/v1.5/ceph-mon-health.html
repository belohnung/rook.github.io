












































<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="ie=edge" />

    
    <meta name="robots" content="noindex">
    

    <title>Ceph Docs</title>

    <link rel="canonical" href="https://rook.io/docs/rook/v1.5/ceph-mon-health.html">

    <link rel="icon" href="/favicon.ico" />
<link rel="icon" type="image/png" href="/images/favicon_16x16.png" sizes="16x16" />
<link rel="icon" type="image/png" href="/images/favicon_32x32.png" sizes="32x32" />
<link rel="icon" type="image/png" href="/images/favicon_48x48.png" sizes="48x48" />
<link rel="icon" type="image/png" href="/images/favicon_192x192.png" sizes="192x192" />


    <link href="//fonts.googleapis.com/css?family=Montserrat:500|Open+Sans:300,400,600" rel="stylesheet">
    
    <link rel="stylesheet" href="/css/main.css">
    
      <link rel="stylesheet" href="/css/docs.css" />
    
  </head>
  <body>
    <nav id="navigation" aria-label="Navigation">
  <div>
    <div class="logo">
      <a href="/"><img src="/images/rook-logo.svg"/></a>
    </div>
    <div
      class="hamburger-controls"
      onclick="if (document.body.classList.contains('menu-open')) { document.body.classList.remove('menu-open') } else { document.body.classList.add('menu-open') }; return false;">
      <span></span> <span></span> <span></span>
    </div>
    <ul class="links">
      <li class="dropdown">
        <a role="button" href="javascript:void(0)">Documentation</a>
        <div class="dropdown-content">
          <a href="/docs/rook/v1.9/">Ceph</a>
          <a href="/docs/cassandra/v1.7/">Cassandra</a>
          <a href="/docs/nfs/v1.7/">NFS</a>
        </div>
      <li class="dropdown">
        <a role="button" href="javascript:void(0)">Community</a>
        <div class="dropdown-content">
          <a href="//github.com/rook/rook">GitHub</a>
          <a href="//slack.rook.io/">Slack</a>
          <a href="//groups.google.com/forum/#!forum/rook-dev">Forum</a>
          <a href="//twitter.com/rook_io">Twitter</a>
        </div>
      </li>
      <li><a href="//blog.rook.io/">Blog</a></li>
      <li><a class="button small" href="/docs/rook/v1.9/quickstart.html">Get Started</a></li>
    </ul>
  </div>
</nav>

    <main id="content" aria-label="Content"><div>



















<section class="docs-header">
  <h1>Ceph</h1>
  <div class="versions">
    <a role="button" href="javascript:void(0)">Rook Ceph v1.5</a>
    <div class="versions-dropdown-content">
      
        <a href="/docs/rook/v1.9/ceph-mon-health.html">Rook Ceph v1.9</a>
      
        <a href="/docs/rook/v1.8/ceph-mon-health.html">Rook Ceph v1.8</a>
      
        <a href="/docs/rook/v1.7/ceph-mon-health.html">Rook Ceph v1.7</a>
      
        <a href="/docs/rook/v1.6/ceph-mon-health.html">Rook Ceph v1.6</a>
      
        <a href="/docs/rook/v1.5/ceph-mon-health.html" class="active">Rook Ceph v1.5</a>
      
        <a href="/docs/rook/v1.4/ceph-mon-health.html">Rook Ceph v1.4</a>
      
        <a href="/docs/rook/v1.3/ceph-mon-health.html">Rook Ceph v1.3</a>
      
        <a href="/docs/rook/v1.2/ceph-mon-health.html">Rook Ceph v1.2</a>
      
        <a href="/docs/rook/v1.1/ceph-mon-health.html">Rook Ceph v1.1</a>
      
        <a href="/docs/rook/v1.0/ceph-mon-health.html">Rook Ceph v1.0</a>
      
        <a href="/docs/rook/v0.9/ceph-mon-health.html">Rook Ceph v0.9</a>
      
        <a href="/docs/rook/v0.8/ceph-mon-health.html">Rook Ceph v0.8</a>
      
        <a href="/docs/rook/v0.7/ceph-mon-health.html">Rook Ceph v0.7</a>
      
        <a href="/docs/rook/v0.6/ceph-mon-health.html">Rook Ceph v0.6</a>
      
        <a href="/docs/rook/v0.5/ceph-mon-health.html">Rook Ceph v0.5</a>
      
        <a href="/docs/rook/latest/ceph-mon-health.html">Rook Ceph latest</a>
      
    </div>
    <img src="/images/arrow.svg" />
  </div>
</section>
<div class="page">
  <div class="docs-menu">
      <ul id="docs-ul"></ul>
  </div>
  <div class="docs-content">
    <div class="docs-actions">
      <a id="edit" href="https://github.com/rook/rook/blob/master/Documentation/ceph-mon-health.md">Edit on GitHub</a>
    </div>
    
      <div class="alert old">
        <p><b>PLEASE NOTE</b>: This document applies to v1.5 version and not to the latest <strong>stable</strong> release v1.9</p>
      </div>
    
    <div class="docs-text">
      <h1 id="monitor-health">Monitor Health</h1>

<p>Failure in a distributed system is to be expected. Ceph was designed from the ground up to deal with the failures of a distributed system.
At the next layer, Rook was designed from the ground up to automate recovery of Ceph components that traditionally required admin intervention.
Monitor health is the most critical piece of the equation that Rook actively monitors. If they are not in a good state,
the operator will take action to restore their health and keep your cluster protected from disaster.</p>

<p>The Ceph monitors (mons) are the brains of the distributed cluster. They control all of the metadata that is necessary
to store and retrieve your data as well as keep it safe. If the monitors are not in a healthy state you will risk losing all the data in your system.</p>

<h2 id="monitor-identity">Monitor Identity</h2>

<p>Each monitor in a Ceph cluster has a static identity. Every component in the cluster is aware of the identity, and that identity
must be immutable. The identity of a mon is its IP address.</p>

<p>To have an immutable IP address in Kubernetes, Rook creates a K8s service for each monitor. The clusterIP of the service will act as the stable identity.</p>

<p>When a monitor pod starts, it will bind to its podIP and it will expect communication to be via its service IP address.</p>

<h2 id="monitor-quorum">Monitor Quorum</h2>

<p>Multiple mons work together to provide redundancy by each keeping a copy of the metadata. A variation of the distributed algorithm Paxos
is used to establish consensus about the state of the cluster. Paxos requires a super-majority of mons to be running in order to establish
quorum and perform operations in the cluster. If the majority of mons are not running, quorum is lost and nothing can be done in the cluster.</p>

<h3 id="how-many-mons">How many mons?</h3>

<p>Most commonly a cluster will have three mons. This would mean that one mon could go down and allow the cluster to remain healthy.
You would still have 2/3 mons running to give you consensus in the cluster for any operation.</p>

<p>You will always want an odd number of mons. Fifty percent of mons will not be sufficient to maintain quorum. If you had two mons and one
of them went down, you would have 1/2 of quorum. Since that is not a super-majority, the cluster would have to wait until the second mon is up again.
Therefore, Rook prohibits an even number of mons.</p>

<p>The number of mons to create in a cluster depends on your tolerance for losing a node. If you have 1 mon zero nodes can be lost
to maintain quorum. With 3 mons one node can be lost, and with 5 mons two nodes can be lost. Because the Rook operator will automatically
start a new new monitor if one dies, you typically only need three mons. The more mons you have, the more overhead there will be to make
a change to the cluster, which could become a performance issue in a large cluster.</p>

<h2 id="mitigating-monitor-failure">Mitigating Monitor Failure</h2>

<p>Whatever the reason that a mon may fail (power failure, software crash, software hang, etc), there are several layers of mitigation in place
to help recover the mon. It is always better to bring an existing mon back up than to failover to bring up a new mon.</p>

<p>The Rook operator creates a mon with a Deployment to ensure that the mon pod will always be restarted if it fails. If a mon pod stops
for any reason, Kubernetes will automatically start the pod up again.</p>

<p>In order for a mon to support a pod/node restart, the mon metadata is persisted to disk, either under the <code class="language-plaintext highlighter-rouge">dataDirHostPath</code> specified
in the CephCluster CR, or in the volume defined by the <code class="language-plaintext highlighter-rouge">volumeClaimTemplate</code> in the CephCluster CR.
This will allow the mon to start back up with its existing metadata and continue where it left off even if the pod had
to be re-created. Without this persistence, the mon cannot restart.</p>

<h2 id="failing-over-a-monitor">Failing over a Monitor</h2>

<p>If a mon is unhealthy and the K8s pod restart or liveness probe are not sufficient to bring a mon back up, the operator will make the decision
to terminate the unhealthy monitor deployment and bring up a new monitor with a new identity.
This is an operation that must be done while mon quorum is maintained by other mons in the cluster.</p>

<p>The operator checks for mon health every 45 seconds. If a monitor is down, the operator will wait 10 minutes before failing over the unhealthy mon.
These two intervals can be configured as parameters to the CephCluster CR (see below). If the intervals are too short, it could be unhealthy if the mons are failed over too aggressively. If the intervals are too long, the cluster could be at risk of losing quorum if a new monitor is not brought up before another mon fails.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">healthCheck</span><span class="pi">:</span>
  <span class="na">daemonHealth</span><span class="pi">:</span>
    <span class="na">mon</span><span class="pi">:</span>
      <span class="na">disabled</span><span class="pi">:</span> <span class="no">false</span>
      <span class="na">interval</span><span class="pi">:</span> <span class="s">45s</span>
      <span class="na">timeout</span><span class="pi">:</span> <span class="s">10m</span>
</code></pre></div></div>

<p>If you want to force a mon to failover for testing or other purposes, you can scale down the mon deployment to 0, then wait
for the timeout. Note that the operator may scale up the mon again automatically if the operator is restarted or if a full
reconcile is triggered, such as when the CephCluster CR is updated.</p>

<p>If the mon pod is in pending state and couldn’t be assigned to a node (say, due to node drain), then the operator will wait for the timeout again before the mon failover. So the timeout waiting for the mon failover will be doubled in this case.</p>

<p>To disable monitor automatic failover, the <code class="language-plaintext highlighter-rouge">timeout</code> can be set to <code class="language-plaintext highlighter-rouge">0</code>, if the monitor goes out of quorum Rook will never fail it over onto another node.
This is especially useful for planned maintenance.</p>

<h3 id="example-failover">Example Failover</h3>

<p>Rook will create mons with pod names such as mon-a, mon-b, and mon-c. Let’s say mon-b had an issue and the pod failed.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl -n rook-ceph get pod -l app=rook-ceph-mon
NAME                               READY   STATUS    RESTARTS   AGE
rook-ceph-mon-a-74dc96545-ch5ns    1/1     Running   0          9m
rook-ceph-mon-b-6b9d895c4c-bcl2h   1/1     Error     2          9m
rook-ceph-mon-c-7d6df6d65c-5cjwl   1/1     Running   0          8m
</code></pre></div></div>

<p>After a failover, you will see the unhealthy mon removed and a new mon added such as mon-d. A fully healthy mon quorum is now running again.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl -n rook-ceph get pod -l app=rook-ceph-mon
NAME                             READY     STATUS    RESTARTS   AGE
rook-ceph-mon-a-74dc96545-ch5ns    1/1     Running   0          19m
rook-ceph-mon-c-7d6df6d65c-5cjwl   1/1     Running   0          18m
rook-ceph-mon-d-9e7ea7e76d-4bhxm   1/1     Running   0          20s
</code></pre></div></div>

<p>From the toolbox we can verify the status of the health mon quorum:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[root@rook-ceph-tools-78cdfd976c-8p6dn /]# ceph -s
  cluster:
    id:     35179270-8a39-4e08-a352-a10c52bb04ff
    health: HEALTH_OK

  services:
    mon: 3 daemons, quorum a,b,d (age 2m)
    mgr: a(active, since 12m)
    osd: 3 osds: 3 up (since 10m), 3 in (since 10m)

  ...
</code></pre></div></div>

    </div>
  </div>
</div>

<script>
  var menu = [];
  var BASE_PATH = "";

  function add(name, url, isChild, current) {
    var item = { name: name, url: url, current: current };
    var container = menu;
    if (isChild && menu.length > 0) {
      menu[menu.length-1].children = menu[menu.length-1].children || [];
      container = menu[menu.length-1].children;
      if (current) {
        menu[menu.length-1].childCurrent = true;
      }
    }
    container.push(item);
  }

  
    add(
      "Rook",
      "/docs/rook/v1.5/",
      false,
      false
    );
  
    add(
      "Quickstart",
      "/docs/rook/v1.5/quickstart.html",
      false,
      false
    );
  
    add(
      "Cassandra",
      "/docs/rook/v1.5/cassandra.html",
      true,
      false
    );
  
    add(
      "Ceph Storage",
      "/docs/rook/v1.5/ceph-quickstart.html",
      true,
      false
    );
  
    add(
      "CockroachDB",
      "/docs/rook/v1.5/cockroachdb.html",
      true,
      false
    );
  
    add(
      "EdgeFS Data Fabric",
      "/docs/rook/v1.5/edgefs-quickstart.html",
      true,
      false
    );
  
    add(
      "Network Filesystem (NFS)",
      "/docs/rook/v1.5/nfs.html",
      true,
      false
    );
  
    add(
      "YugabyteDB",
      "/docs/rook/v1.5/yugabytedb.html",
      true,
      false
    );
  
    add(
      "Prerequisites",
      "/docs/rook/v1.5/k8s-pre-reqs.html",
      false,
      false
    );
  
    add(
      "FlexVolume Configuration",
      "/docs/rook/v1.5/flexvolume.html",
      true,
      false
    );
  
    add(
      "Ceph Storage",
      "/docs/rook/v1.5/ceph-storage.html",
      false,
      false
    );
  
    add(
      "Prerequisites",
      "/docs/rook/v1.5/ceph-prerequisites.html",
      true,
      false
    );
  
    add(
      "Admission Controller",
      "/docs/rook/v1.5/admission-controller-usage.html",
      true,
      false
    );
  
    add(
      "Examples",
      "/docs/rook/v1.5/ceph-examples.html",
      true,
      false
    );
  
    add(
      "OpenShift",
      "/docs/rook/v1.5/ceph-openshift.html",
      true,
      false
    );
  
    add(
      "Block Storage",
      "/docs/rook/v1.5/ceph-block.html",
      true,
      false
    );
  
    add(
      "Object Storage",
      "/docs/rook/v1.5/ceph-object.html",
      true,
      false
    );
  
    add(
      "Object Multisite",
      "/docs/rook/v1.5/ceph-object-multisite.html",
      true,
      false
    );
  
    add(
      "Shared Filesystem",
      "/docs/rook/v1.5/ceph-filesystem.html",
      true,
      false
    );
  
    add(
      "Ceph Dashboard",
      "/docs/rook/v1.5/ceph-dashboard.html",
      true,
      false
    );
  
    add(
      "Prometheus Monitoring",
      "/docs/rook/v1.5/ceph-monitoring.html",
      true,
      false
    );
  
    add(
      "Cluster CRD",
      "/docs/rook/v1.5/ceph-cluster-crd.html",
      true,
      false
    );
  
    add(
      "Block Pool CRD",
      "/docs/rook/v1.5/ceph-pool-crd.html",
      true,
      false
    );
  
    add(
      "Object Store CRD",
      "/docs/rook/v1.5/ceph-object-store-crd.html",
      true,
      false
    );
  
    add(
      "Object Multisite CRDs",
      "/docs/rook/v1.5/ceph-object-multisite-crd.html",
      true,
      false
    );
  
    add(
      "Object Bucket Claim",
      "/docs/rook/v1.5/ceph-object-bucket-claim.html",
      true,
      false
    );
  
    add(
      "Object Store User CRD",
      "/docs/rook/v1.5/ceph-object-store-user-crd.html",
      true,
      false
    );
  
    add(
      "Shared Filesystem CRD",
      "/docs/rook/v1.5/ceph-filesystem-crd.html",
      true,
      false
    );
  
    add(
      "NFS CRD",
      "/docs/rook/v1.5/ceph-nfs-crd.html",
      true,
      false
    );
  
    add(
      "Ceph CSI",
      "/docs/rook/v1.5/ceph-csi-drivers.html",
      true,
      false
    );
  
    add(
      "Volume clone",
      "/docs/rook/v1.5/ceph-csi-volume-clone.html",
      true,
      false
    );
  
    add(
      "Snapshots",
      "/docs/rook/v1.5/ceph-csi-snapshot.html",
      true,
      false
    );
  
    add(
      "RBDMirror CRD",
      "/docs/rook/v1.5/ceph-rbd-mirror-crd.html",
      true,
      false
    );
  
    add(
      "Client CRD",
      "/docs/rook/v1.5/ceph-client-crd.html",
      true,
      false
    );
  
    add(
      "Configuration",
      "/docs/rook/v1.5/ceph-configuration.html",
      true,
      false
    );
  
    add(
      "Upgrades",
      "/docs/rook/v1.5/ceph-upgrade.html",
      true,
      false
    );
  
    add(
      "Cleanup",
      "/docs/rook/v1.5/ceph-teardown.html",
      true,
      false
    );
  
    add(
      "EdgeFS Data Fabric",
      "/docs/rook/v1.5/edgefs-storage.html",
      false,
      false
    );
  
    add(
      "Cluster CRD",
      "/docs/rook/v1.5/edgefs-cluster-crd.html",
      true,
      false
    );
  
    add(
      "ISGW Link CRD",
      "/docs/rook/v1.5/edgefs-isgw-crd.html",
      true,
      false
    );
  
    add(
      "Scale-Out NFS CRD",
      "/docs/rook/v1.5/edgefs-nfs-crd.html",
      true,
      false
    );
  
    add(
      "Scale-Out SMB CRD",
      "/docs/rook/v1.5/edgefs-smb-crd.html",
      true,
      false
    );
  
    add(
      "Edge-X S3 CRD",
      "/docs/rook/v1.5/edgefs-s3x-crd.html",
      true,
      false
    );
  
    add(
      "AWS S3 CRD",
      "/docs/rook/v1.5/edgefs-s3-crd.html",
      true,
      false
    );
  
    add(
      "OpenStack/SWIFT CRD",
      "/docs/rook/v1.5/edgefs-swift-crd.html",
      true,
      false
    );
  
    add(
      "iSCSI Target CRD",
      "/docs/rook/v1.5/edgefs-iscsi-crd.html",
      true,
      false
    );
  
    add(
      "CSI driver",
      "/docs/rook/v1.5/edgefs-csi.html",
      true,
      false
    );
  
    add(
      "Monitoring",
      "/docs/rook/v1.5/edgefs-monitoring.html",
      true,
      false
    );
  
    add(
      "User Interface",
      "/docs/rook/v1.5/edgefs-ui.html",
      true,
      false
    );
  
    add(
      "VDEV Management",
      "/docs/rook/v1.5/edgefs-vdev-management.html",
      true,
      false
    );
  
    add(
      "Upgrade",
      "/docs/rook/v1.5/edgefs-upgrade.html",
      true,
      false
    );
  
    add(
      "Cassandra Cluster CRD",
      "/docs/rook/v1.5/cassandra-cluster-crd.html",
      false,
      false
    );
  
    add(
      "Upgrade",
      "/docs/rook/v1.5/cassandra-operator-upgrade.html",
      true,
      false
    );
  
    add(
      "CockroachDB Cluster CRD",
      "/docs/rook/v1.5/cockroachdb-cluster-crd.html",
      false,
      false
    );
  
    add(
      "NFS Server CRD",
      "/docs/rook/v1.5/nfs-crd.html",
      false,
      false
    );
  
    add(
      "YugabyteDB Cluster CRD",
      "/docs/rook/v1.5/yugabytedb-cluster-crd.html",
      false,
      false
    );
  
    add(
      "Helm Charts",
      "/docs/rook/v1.5/helm.html",
      false,
      false
    );
  
    add(
      "Ceph Operator",
      "/docs/rook/v1.5/helm-operator.html",
      true,
      false
    );
  
    add(
      "Common Issues",
      "/docs/rook/v1.5/common-issues.html",
      false,
      false
    );
  
    add(
      "Ceph Tools",
      "/docs/rook/v1.5/ceph-tools.html",
      false,
      false
    );
  
    add(
      "Toolbox",
      "/docs/rook/v1.5/ceph-toolbox.html",
      true,
      false
    );
  
    add(
      "Common Issues",
      "/docs/rook/v1.5/ceph-common-issues.html",
      true,
      false
    );
  
    add(
      "CSI Common Issues",
      "/docs/rook/v1.5/ceph-csi-troubleshooting.html",
      true,
      false
    );
  
    add(
      "Monitor Health",
      "/docs/rook/v1.5/ceph-mon-health.html",
      true,
      true
    );
  
    add(
      "OSD Management",
      "/docs/rook/v1.5/ceph-osd-mgmt.html",
      true,
      false
    );
  
    add(
      "Direct Tools",
      "/docs/rook/v1.5/direct-tools.html",
      true,
      false
    );
  
    add(
      "Advanced Configuration",
      "/docs/rook/v1.5/ceph-advanced-configuration.html",
      true,
      false
    );
  
    add(
      "OpenShift Common Issues",
      "/docs/rook/v1.5/ceph-openshift-issues.html",
      true,
      false
    );
  
    add(
      "Disaster Recovery",
      "/docs/rook/v1.5/ceph-disaster-recovery.html",
      true,
      false
    );
  
    add(
      "Tectonic Configuration",
      "/docs/rook/v1.5/tectonic.html",
      true,
      false
    );
  
    add(
      "Contributing",
      "/docs/rook/v1.5/development-flow.html",
      false,
      false
    );
  
    add(
      "Storage Providers",
      "/docs/rook/v1.5/storage-providers.html",
      true,
      false
    );
  
    add(
      "Multi-Node Test Environment",
      "/docs/rook/v1.5/development-environment.html",
      true,
      false
    );
  

  function getEntry(item) {
    var itemDom = document.createElement('li');

    if (item.current) {
      itemDom.innerHTML = item.name;
      itemDom.classList.add('current');
    } else {
      itemDom.innerHTML = '<a href="' + item.url + '">' + item.name + '</a>';
    }

    return itemDom;
  }

  // Flush css changes as explained in: https://stackoverflow.com/a/34726346
  // and more completely: https://stackoverflow.com/a/6956049
  function flushCss(element) {
    element.offsetHeight;
  }

  function addArrow(itemDom) {
    var MAIN_ITEM_HEIGHT = 24;
    var BOTTOM_PADDING = 20;
    var arrowDom = document.createElement('a');
    arrowDom.classList.add('arrow');
    arrowDom.innerHTML = '<img src="' + BASE_PATH + '/images/arrow.svg" />';
    arrowDom.onclick = function(itemDom) {
      return function () {
        // Calculated full height of the opened list
        var fullHeight = MAIN_ITEM_HEIGHT + BOTTOM_PADDING + itemDom.lastChild.clientHeight + 'px';

        itemDom.classList.toggle('open');

        if (itemDom.classList.contains('open')) {
          itemDom.style.height = fullHeight;
        } else {
          // If the list height is auto we have to set it to fullHeight
          // without tranistion before we shrink it to collapsed height
          if (itemDom.style.height === 'auto') {
            itemDom.style.transition = 'none';
            itemDom.style.height = fullHeight;
            flushCss(itemDom);
            itemDom.style.transition = '';
          }
          itemDom.style.height = MAIN_ITEM_HEIGHT + 'px';
        }

        return false;
      };
    }(itemDom);
    itemDom.appendChild(arrowDom);

    if ((item.current && item.children) || item.childCurrent) {
      itemDom.classList.add('open');
      itemDom.style.height = 'auto';
    } else {
      itemDom.style.height = MAIN_ITEM_HEIGHT + 'px';
    }
  }

  var menuDom = document.getElementById('docs-ul');
  for (var i = 0; i < menu.length; i++) {
    var item = menu[i];
    var itemDom = getEntry(item);

    if (item.childCurrent) {
      itemDom.classList.add('childCurrent');
    }

    if (item.children) {
      addArrow(itemDom);
      itemDom.classList.add('children');
      var children = document.createElement('ul');
      for (var j = 0; j < item.children.length; j++) {
        children.appendChild(getEntry(item.children[j]));
      }
      itemDom.appendChild(children);
    }
    menuDom.appendChild(itemDom);
  }
</script>
</div></main>
    <footer id="footer" aria-label="Footer">
  <div class="top">
    <a href="//www.cncf.io">
      <img
        class="cncf"
        src="/images/cncf.png"
        srcset="/images/cncf@2x.png 2x, /images/cncf@3x.png 3x" />
    </a>
    <p>We are a Cloud Native Computing Foundation graduated project.</p>
  </div>
  <div class="middle">
    <div class="grid-center">
      <div class="col_sm-12">
        <span>Getting Started</span>
        <a href="//github.com/rook/rook">GitHub</a>
        <a href="/docs/rook/v1.9/">Documentation</a>
        <a href="//github.com/rook/rook/blob/master/CONTRIBUTING.md#how-to-contribute">How to Contribute</a>
      </div>
      <div class="col_sm-12">
        <span>Community</span>
        <a href="//slack.rook.io/">Slack</a>
        <a href="//twitter.com/rook_io">Twitter</a>
        <a href="//groups.google.com/forum/#!forum/rook-dev">Forum</a>
        <a href="//blog.rook.io/">Blog</a>
      </div>
      <div class="col_sm-12">
        <span>Contact</span>
        <a href="mailto:cncf-rook-info@lists.cncf.io">Email</a>
        <a href="//github.com/rook/rook/issues">Feature request</a>
      </div>
      <div class="col_sm-12">
        <span>Top Contributors</span>
        <a href="//cloudical.io/">Cloudical</a>
        <a href="//cybozu.com">Cybozu, Inc</a>
        <a href="//www.redhat.com">Red Hat</a>
        <a href="//www.suse.com/">SUSE</a>
        <a href="//upbound.io">Upbound</a>
      </div>
    </div>
  </div>
  <div class="bottom">
    <div class="grid-center">
      <div class="col-8">
        <a class="logo" href="/">
          <img src="/images/rook-logo-small.svg" alt="rook.io" />
        </a>
        <p>
          &#169; Rook Authors 2022. Documentation distributed under
          <a href="https://creativecommons.org/licenses/by/4.0">CC-BY-4.0</a>.
        </p>
        <p>
          &#169; 2022 The Linux Foundation. All rights reserved. The Linux Foundation has
          registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our
          <a href="https://www.linuxfoundation.org/trademark-usage/">Trademark Usage</a> page.
        </p>
      </div>
    </div>
  </div>
</footer>


  <script src="/js/anchor.js"></script>
  <script>
    anchors.options = {
      placement: 'right',
      icon: '#',
    }

    document.addEventListener('DOMContentLoaded', function(event) {
      anchors.add('.docs-text h1, .docs-text h2, .docs-text h3, .docs-text h4, .docs-text h5, .docs-text h6');
    });
  </script>




    
  </body>
</html>
