












































<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="ie=edge" />

    
    <meta name="robots" content="noindex">
    

    <title>Ceph Docs</title>

    <link rel="canonical" href="https://rook.io/docs/rook/v1.6/ceph-teardown.html">

    <link rel="icon" href="/favicon.ico" />
<link rel="icon" type="image/png" href="/images/favicon_16x16.png" sizes="16x16" />
<link rel="icon" type="image/png" href="/images/favicon_32x32.png" sizes="32x32" />
<link rel="icon" type="image/png" href="/images/favicon_48x48.png" sizes="48x48" />
<link rel="icon" type="image/png" href="/images/favicon_192x192.png" sizes="192x192" />


    <link href="//fonts.googleapis.com/css?family=Montserrat:500|Open+Sans:300,400,600" rel="stylesheet">
    
    <link rel="stylesheet" href="/css/main.css">
    
      <link rel="stylesheet" href="/css/docs.css" />
    
  </head>
  <body>
    <nav id="navigation" aria-label="Navigation">
  <div>
    <div class="logo">
      <a href="/"><img src="/images/rook-logo.svg"/></a>
    </div>
    <div
      class="hamburger-controls"
      onclick="if (document.body.classList.contains('menu-open')) { document.body.classList.remove('menu-open') } else { document.body.classList.add('menu-open') }; return false;">
      <span></span> <span></span> <span></span>
    </div>
    <ul class="links">
      <li class="dropdown">
        <a role="button" href="javascript:void(0)">Documentation</a>
        <div class="dropdown-content">
          <a href="/docs/rook/v1.9/">Ceph</a>
          <a href="/docs/cassandra/v1.7/">Cassandra</a>
          <a href="/docs/nfs/v1.7/">NFS</a>
        </div>
      <li class="dropdown">
        <a role="button" href="javascript:void(0)">Community</a>
        <div class="dropdown-content">
          <a href="//github.com/rook/rook">GitHub</a>
          <a href="//slack.rook.io/">Slack</a>
          <a href="//groups.google.com/forum/#!forum/rook-dev">Forum</a>
          <a href="//twitter.com/rook_io">Twitter</a>
        </div>
      </li>
      <li><a href="//blog.rook.io/">Blog</a></li>
      <li><a class="button small" href="/docs/rook/v1.9/quickstart.html">Get Started</a></li>
    </ul>
  </div>
</nav>

    <main id="content" aria-label="Content"><div>



















<section class="docs-header">
  <h1>Ceph</h1>
  <div class="versions">
    <a role="button" href="javascript:void(0)">Rook Ceph v1.6</a>
    <div class="versions-dropdown-content">
      
        <a href="/docs/rook/v1.9/ceph-teardown.html">Rook Ceph v1.9</a>
      
        <a href="/docs/rook/v1.8/ceph-teardown.html">Rook Ceph v1.8</a>
      
        <a href="/docs/rook/v1.7/ceph-teardown.html">Rook Ceph v1.7</a>
      
        <a href="/docs/rook/v1.6/ceph-teardown.html" class="active">Rook Ceph v1.6</a>
      
        <a href="/docs/rook/v1.5/ceph-teardown.html">Rook Ceph v1.5</a>
      
        <a href="/docs/rook/v1.4/ceph-teardown.html">Rook Ceph v1.4</a>
      
        <a href="/docs/rook/v1.3/ceph-teardown.html">Rook Ceph v1.3</a>
      
        <a href="/docs/rook/v1.2/ceph-teardown.html">Rook Ceph v1.2</a>
      
        <a href="/docs/rook/v1.1/ceph-teardown.html">Rook Ceph v1.1</a>
      
        <a href="/docs/rook/v1.0/ceph-teardown.html">Rook Ceph v1.0</a>
      
        <a href="/docs/rook/v0.9/ceph-teardown.html">Rook Ceph v0.9</a>
      
        <a href="/docs/rook/v0.8/ceph-teardown.html">Rook Ceph v0.8</a>
      
        <a href="/docs/rook/v0.7/ceph-teardown.html">Rook Ceph v0.7</a>
      
        <a href="/docs/rook/v0.6/ceph-teardown.html">Rook Ceph v0.6</a>
      
        <a href="/docs/rook/v0.5/ceph-teardown.html">Rook Ceph v0.5</a>
      
        <a href="/docs/rook/latest/ceph-teardown.html">Rook Ceph latest</a>
      
    </div>
    <img src="/images/arrow.svg" />
  </div>
</section>
<div class="page">
  <div class="docs-menu">
      <ul id="docs-ul"></ul>
  </div>
  <div class="docs-content">
    <div class="docs-actions">
      <a id="edit" href="https://github.com/rook/rook/blob/master/Documentation/ceph-teardown.md">Edit on GitHub</a>
    </div>
    
      <div class="alert old">
        <p><b>PLEASE NOTE</b>: This document applies to v1.6 version and not to the latest <strong>stable</strong> release v1.9</p>
      </div>
    
    <div class="docs-text">
      <h1 id="cleaning-up-a-cluster">Cleaning up a Cluster</h1>

<p>If you want to tear down the cluster and bring up a new one, be aware of the following resources that will need to be cleaned up:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">rook-ceph</code> namespace: The Rook operator and cluster created by <code class="language-plaintext highlighter-rouge">operator.yaml</code> and <code class="language-plaintext highlighter-rouge">cluster.yaml</code> (the cluster CRD)</li>
  <li><code class="language-plaintext highlighter-rouge">/var/lib/rook</code>: Path on each host in the cluster where configuration is cached by the ceph mons and osds</li>
</ul>

<p>Note that if you changed the default namespaces or paths such as <code class="language-plaintext highlighter-rouge">dataDirHostPath</code> in the sample yaml files, you will need to adjust these namespaces and paths throughout these instructions.</p>

<p>If you see issues tearing down the cluster, see the <a href="#troubleshooting">Troubleshooting</a> section below.</p>

<p>If you are tearing down a cluster frequently for development purposes, it is instead recommended to use an environment such as Minikube that can easily be reset without worrying about any of these steps.</p>

<h2 id="delete-the-block-and-file-artifacts">Delete the Block and File artifacts</h2>

<p>First you will need to clean up the resources created on top of the Rook cluster.</p>

<p>These commands will clean up the resources from the <a href="/docs/rook/v1.6/ceph-block.html#teardown">block</a> and <a href="/docs/rook/v1.6/ceph-filesystem.html#teardown">file</a> walkthroughs (unmount volumes, delete volume claims, etc). If you did not complete those parts of the walkthrough, you can skip these instructions:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">kubectl delete -f ../wordpress.yaml
kubectl delete -f ../mysql.yaml
kubectl delete -n rook-ceph cephblockpool replicapool
kubectl delete storageclass rook-ceph-block
kubectl delete -f csi/cephfs/kube-registry.yaml
kubectl delete storageclass csi-cephfs
</span></code></pre></div></div>

<p>After those block and file resources have been cleaned up, you can then delete your Rook cluster. This is important to delete <strong>before removing the Rook operator and agent or else resources may not be cleaned up properly</strong>.</p>

<h2 id="delete-the-cephcluster-crd">Delete the CephCluster CRD</h2>

<p>Edit the <code class="language-plaintext highlighter-rouge">CephCluster</code> and add the <code class="language-plaintext highlighter-rouge">cleanupPolicy</code></p>

<p>WARNING: DATA WILL BE PERMANENTLY DELETED AFTER DELETING THE <code class="language-plaintext highlighter-rouge">CephCluster</code> CR WITH <code class="language-plaintext highlighter-rouge">cleanupPolicy</code>.</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">kubectl -n rook-ceph patch cephcluster rook-ceph --type merge -p '{"spec":{"cleanupPolicy":{"confirmation":"yes-really-destroy-data"}}}'
</span></code></pre></div></div>

<p>Once the cleanup policy is enabled, any new configuration changes in the CephCluster will be blocked. Nothing will happen until the deletion of the CR is requested, so this <code class="language-plaintext highlighter-rouge">cleanupPolicy</code> change can still be reverted if needed.</p>

<p>Checkout more details about the <code class="language-plaintext highlighter-rouge">cleanupPolicy</code> <a href="/docs/rook/v1.6/ceph-cluster-crd.html#cleanup-policy">here</a></p>

<p>Delete the <code class="language-plaintext highlighter-rouge">CephCluster</code> CR.</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">kubectl -n rook-ceph delete cephcluster rook-ceph
</span></code></pre></div></div>

<p>Verify that the cluster CR has been deleted before continuing to the next step.</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">kubectl -n rook-ceph get cephcluster
</span></code></pre></div></div>

<p>If the <code class="language-plaintext highlighter-rouge">cleanupPolicy</code> was applied, then wait for the <code class="language-plaintext highlighter-rouge">rook-ceph-cleanup</code> jobs to be completed on all the nodes.
These jobs will perform the following operations:</p>
<ul>
  <li>Delete the directory <code class="language-plaintext highlighter-rouge">/var/lib/rook</code> (or the path specified by the <code class="language-plaintext highlighter-rouge">dataDirHostPath</code>) on all the nodes</li>
  <li>Wipe the data on the drives on all the nodes where OSDs were running in this cluster</li>
</ul>

<p>Note: The cleanup jobs might not start if the resources created on top of Rook Cluster are not deleted completely. <a href="/docs/rook/v1.6/ceph-teardown.html#delete-the-block-and-file-artifacts">See</a></p>

<h2 id="delete-the-operator-and-related-resources">Delete the Operator and related Resources</h2>

<p>This will begin the process of the Rook Ceph operator and all other resources being cleaned up.
This includes related resources such as the agent and discover daemonsets with the following commands:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">kubectl delete -f operator.yaml
kubectl delete -f common.yaml
kubectl delete -f crds.yaml
</span></code></pre></div></div>

<p>If the <code class="language-plaintext highlighter-rouge">cleanupPolicy</code> was applied and the cleanup jobs have completed on all the nodes, then the cluster tear down has been successful. If you skipped adding the <code class="language-plaintext highlighter-rouge">cleanupPolicy</code> then follow the manual steps mentioned below to tear down the cluster.</p>

<h2 id="delete-the-data-on-hosts">Delete the data on hosts</h2>

<blockquote>
  <p><strong>IMPORTANT</strong>: The final cleanup step requires deleting files on each host in the cluster. All files under the <code class="language-plaintext highlighter-rouge">dataDirHostPath</code> property specified in the cluster CRD will need to be deleted. Otherwise, inconsistent state will remain when a new cluster is started.</p>
</blockquote>

<p>Connect to each machine and delete <code class="language-plaintext highlighter-rouge">/var/lib/rook</code>, or the path specified by the <code class="language-plaintext highlighter-rouge">dataDirHostPath</code>.</p>

<p>In the future this step will not be necessary when we build on the K8s local storage feature.</p>

<p>If you modified the demo settings, additional cleanup is up to you for devices, host paths, etc.</p>

<h3 id="zapping-devices">Zapping Devices</h3>

<p>Disks on nodes used by Rook for osds can be reset to a usable state with the following methods:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">#</span><span class="o">!</span>/usr/bin/env bash
<span class="go">DISK="/dev/sdb"

</span><span class="gp">#</span><span class="w"> </span>Zap the disk to a fresh, usable state <span class="o">(</span>zap-all is important, b/c MBR has to be clean<span class="o">)</span>
<span class="go">
</span><span class="gp">#</span><span class="w"> </span>You will have to run this step <span class="k">for </span>all disks.
<span class="gp">sgdisk --zap-all $</span>DISK
<span class="go">
</span><span class="gp">#</span><span class="w"> </span>Clean hdds with <span class="nb">dd</span>
<span class="gp">dd if=/dev/zero of="$</span>DISK<span class="s2">" bs=1M count=100 oflag=direct,dsync
</span><span class="go">
</span><span class="gp">#</span><span class="w"> </span>Clean disks such as ssd with blkdiscard instead of <span class="nb">dd</span>
<span class="gp">blkdiscard $</span>DISK
<span class="go">
</span><span class="gp">#</span><span class="w"> </span>These steps only have to be run once on each node
<span class="gp">#</span><span class="w"> </span>If rook sets up osds using ceph-volume, teardown leaves some devices mapped that lock the disks.
<span class="go">ls /dev/mapper/ceph-* | xargs -I% -- dmsetup remove %

</span><span class="gp">#</span><span class="w"> </span>ceph-volume setup can leave ceph-&lt;UUID&gt; directories <span class="k">in</span> /dev and /dev/mapper <span class="o">(</span>unnecessary clutter<span class="o">)</span>
<span class="go">rm -rf /dev/ceph-*
rm -rf /dev/mapper/ceph--*

</span><span class="gp">#</span><span class="w"> </span>Inform the OS of partition table changes
<span class="gp">partprobe $</span>DISK
</code></pre></div></div>

<h2 id="troubleshooting">Troubleshooting</h2>

<p>If the cleanup instructions are not executed in the order above, or you otherwise have difficulty cleaning up the cluster, here are a few things to try.</p>

<p>The most common issue cleaning up the cluster is that the <code class="language-plaintext highlighter-rouge">rook-ceph</code> namespace or the cluster CRD remain indefinitely in the <code class="language-plaintext highlighter-rouge">terminating</code> state. A namespace cannot be removed until all of its resources are removed, so look at which resources are pending termination.</p>

<p>Look at the pods:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">kubectl -n rook-ceph get pod
</span></code></pre></div></div>

<p>If a pod is still terminating, you will need to wait or else attempt to forcefully terminate it (<code class="language-plaintext highlighter-rouge">kubectl delete pod &lt;name&gt;</code>).</p>

<p>Now look at the cluster CRD:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">kubectl -n rook-ceph get cephcluster
</span></code></pre></div></div>

<p>If the cluster CRD still exists even though you have executed the delete command earlier, see the next section on removing the finalizer.</p>

<h3 id="removing-the-cluster-crd-finalizer">Removing the Cluster CRD Finalizer</h3>

<p>When a Cluster CRD is created, a <a href="https://kubernetes.io/docs/tasks/access-kubernetes-api/extend-api-custom-resource-definitions/#finalizers">finalizer</a> is added automatically by the Rook operator. The finalizer will allow the operator to ensure that before the cluster CRD is deleted, all block and file mounts will be cleaned up. Without proper cleanup, pods consuming the storage will be hung indefinitely until a system reboot.</p>

<p>The operator is responsible for removing the finalizer after the mounts have been cleaned up.
If for some reason the operator is not able to remove the finalizer (ie. the operator is not running anymore), you can delete the finalizer manually with the following command:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">for CRD in $</span><span class="o">(</span>kubectl get crd <span class="nt">-n</span> rook-ceph | <span class="nb">awk</span> <span class="s1">'/ceph.rook.io/ {print $1}'</span><span class="o">)</span><span class="p">;</span> <span class="k">do</span>
<span class="gp">    kubectl get -n rook-ceph "$</span>CRD<span class="s2">" -o name | </span><span class="se">\</span><span class="s2">
    xargs -I {} kubectl patch {} --type merge -p '{"</span>metadata<span class="s2">":{"</span>finalizers<span class="s2">": [null]}}'
</span><span class="go">done
</span></code></pre></div></div>

<p>This command will patch the following CRDs on v1.3:</p>
<blockquote>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cephblockpools.ceph.rook.io
cephclients.ceph.rook.io
cephfilesystems.ceph.rook.io
cephnfses.ceph.rook.io
cephobjectstores.ceph.rook.io
cephobjectstoreusers.ceph.rook.io
</code></pre></div>  </div>
</blockquote>

<p>Within a few seconds you should see that the cluster CRD has been deleted and will no longer block other cleanup such as deleting the <code class="language-plaintext highlighter-rouge">rook-ceph</code> namespace.</p>

<p>If the namespace is still stuck in Terminating state, you can check which resources are holding up the deletion and remove the finalizers and delete those</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">kubectl api-resources --verbs=list --namespaced -o name \
  | xargs -n 1 kubectl get --show-kind --ignore-not-found -n rook-ceph
</span></code></pre></div></div>

    </div>
  </div>
</div>

<script>
  var menu = [];
  var BASE_PATH = "";

  function add(name, url, isChild, current) {
    var item = { name: name, url: url, current: current };
    var container = menu;
    if (isChild && menu.length > 0) {
      menu[menu.length-1].children = menu[menu.length-1].children || [];
      container = menu[menu.length-1].children;
      if (current) {
        menu[menu.length-1].childCurrent = true;
      }
    }
    container.push(item);
  }

  
    add(
      "Rook",
      "/docs/rook/v1.6/",
      false,
      false
    );
  
    add(
      "Quickstart",
      "/docs/rook/v1.6/quickstart.html",
      false,
      false
    );
  
    add(
      "Cassandra",
      "/docs/rook/v1.6/cassandra.html",
      true,
      false
    );
  
    add(
      "Ceph Storage",
      "/docs/rook/v1.6/ceph-quickstart.html",
      true,
      false
    );
  
    add(
      "Network Filesystem (NFS)",
      "/docs/rook/v1.6/nfs.html",
      true,
      false
    );
  
    add(
      "Prerequisites",
      "/docs/rook/v1.6/k8s-pre-reqs.html",
      false,
      false
    );
  
    add(
      "FlexVolume Configuration",
      "/docs/rook/v1.6/flexvolume.html",
      true,
      false
    );
  
    add(
      "Ceph Storage",
      "/docs/rook/v1.6/ceph-storage.html",
      false,
      false
    );
  
    add(
      "Prerequisites",
      "/docs/rook/v1.6/ceph-prerequisites.html",
      true,
      false
    );
  
    add(
      "Admission Controller",
      "/docs/rook/v1.6/admission-controller-usage.html",
      true,
      false
    );
  
    add(
      "Examples",
      "/docs/rook/v1.6/ceph-examples.html",
      true,
      false
    );
  
    add(
      "OpenShift",
      "/docs/rook/v1.6/ceph-openshift.html",
      true,
      false
    );
  
    add(
      "Block Storage",
      "/docs/rook/v1.6/ceph-block.html",
      true,
      false
    );
  
    add(
      "Object Storage",
      "/docs/rook/v1.6/ceph-object.html",
      true,
      false
    );
  
    add(
      "Object Multisite",
      "/docs/rook/v1.6/ceph-object-multisite.html",
      true,
      false
    );
  
    add(
      "Shared Filesystem",
      "/docs/rook/v1.6/ceph-filesystem.html",
      true,
      false
    );
  
    add(
      "Ceph Dashboard",
      "/docs/rook/v1.6/ceph-dashboard.html",
      true,
      false
    );
  
    add(
      "Prometheus Monitoring",
      "/docs/rook/v1.6/ceph-monitoring.html",
      true,
      false
    );
  
    add(
      "Cluster CRD",
      "/docs/rook/v1.6/ceph-cluster-crd.html",
      true,
      false
    );
  
    add(
      "Block Pool CRD",
      "/docs/rook/v1.6/ceph-pool-crd.html",
      true,
      false
    );
  
    add(
      "Object Store CRD",
      "/docs/rook/v1.6/ceph-object-store-crd.html",
      true,
      false
    );
  
    add(
      "Object Multisite CRDs",
      "/docs/rook/v1.6/ceph-object-multisite-crd.html",
      true,
      false
    );
  
    add(
      "Object Bucket Claim",
      "/docs/rook/v1.6/ceph-object-bucket-claim.html",
      true,
      false
    );
  
    add(
      "Object Store User CRD",
      "/docs/rook/v1.6/ceph-object-store-user-crd.html",
      true,
      false
    );
  
    add(
      "Shared Filesystem CRD",
      "/docs/rook/v1.6/ceph-filesystem-crd.html",
      true,
      false
    );
  
    add(
      "NFS CRD",
      "/docs/rook/v1.6/ceph-nfs-crd.html",
      true,
      false
    );
  
    add(
      "Ceph CSI",
      "/docs/rook/v1.6/ceph-csi-drivers.html",
      true,
      false
    );
  
    add(
      "Snapshots",
      "/docs/rook/v1.6/ceph-csi-snapshot.html",
      true,
      false
    );
  
    add(
      "Volume clone",
      "/docs/rook/v1.6/ceph-csi-volume-clone.html",
      true,
      false
    );
  
    add(
      "RBDMirror CRD",
      "/docs/rook/v1.6/ceph-rbd-mirror-crd.html",
      true,
      false
    );
  
    add(
      "Client CRD",
      "/docs/rook/v1.6/ceph-client-crd.html",
      true,
      false
    );
  
    add(
      "FilesystemMirror CRD",
      "/docs/rook/v1.6/ceph-fs-mirror-crd.html",
      true,
      false
    );
  
    add(
      "Configuration",
      "/docs/rook/v1.6/ceph-configuration.html",
      true,
      false
    );
  
    add(
      "Upgrades",
      "/docs/rook/v1.6/ceph-upgrade.html",
      true,
      false
    );
  
    add(
      "Cleanup",
      "/docs/rook/v1.6/ceph-teardown.html",
      true,
      true
    );
  
    add(
      "Cassandra Cluster CRD",
      "/docs/rook/v1.6/cassandra-cluster-crd.html",
      false,
      false
    );
  
    add(
      "Upgrade",
      "/docs/rook/v1.6/cassandra-operator-upgrade.html",
      true,
      false
    );
  
    add(
      "NFS Server CRD",
      "/docs/rook/v1.6/nfs-crd.html",
      false,
      false
    );
  
    add(
      "Helm Charts",
      "/docs/rook/v1.6/helm.html",
      false,
      false
    );
  
    add(
      "Ceph Operator",
      "/docs/rook/v1.6/helm-operator.html",
      true,
      false
    );
  
    add(
      "Ceph Cluster",
      "/docs/rook/v1.6/helm-ceph-cluster.html",
      true,
      false
    );
  
    add(
      "Common Issues",
      "/docs/rook/v1.6/common-issues.html",
      false,
      false
    );
  
    add(
      "Ceph Tools",
      "/docs/rook/v1.6/ceph-tools.html",
      false,
      false
    );
  
    add(
      "Toolbox",
      "/docs/rook/v1.6/ceph-toolbox.html",
      true,
      false
    );
  
    add(
      "Common Issues",
      "/docs/rook/v1.6/ceph-common-issues.html",
      true,
      false
    );
  
    add(
      "CSI Common Issues",
      "/docs/rook/v1.6/ceph-csi-troubleshooting.html",
      true,
      false
    );
  
    add(
      "Monitor Health",
      "/docs/rook/v1.6/ceph-mon-health.html",
      true,
      false
    );
  
    add(
      "OSD Management",
      "/docs/rook/v1.6/ceph-osd-mgmt.html",
      true,
      false
    );
  
    add(
      "Direct Tools",
      "/docs/rook/v1.6/direct-tools.html",
      true,
      false
    );
  
    add(
      "Advanced Configuration",
      "/docs/rook/v1.6/ceph-advanced-configuration.html",
      true,
      false
    );
  
    add(
      "OpenShift Common Issues",
      "/docs/rook/v1.6/ceph-openshift-issues.html",
      true,
      false
    );
  
    add(
      "Disaster Recovery",
      "/docs/rook/v1.6/ceph-disaster-recovery.html",
      true,
      false
    );
  
    add(
      "Tectonic Configuration",
      "/docs/rook/v1.6/tectonic.html",
      true,
      false
    );
  
    add(
      "Contributing",
      "/docs/rook/v1.6/development-flow.html",
      false,
      false
    );
  
    add(
      "Storage Providers",
      "/docs/rook/v1.6/storage-providers.html",
      true,
      false
    );
  
    add(
      "Multi-Node Test Environment",
      "/docs/rook/v1.6/development-environment.html",
      true,
      false
    );
  

  function getEntry(item) {
    var itemDom = document.createElement('li');

    if (item.current) {
      itemDom.innerHTML = item.name;
      itemDom.classList.add('current');
    } else {
      itemDom.innerHTML = '<a href="' + item.url + '">' + item.name + '</a>';
    }

    return itemDom;
  }

  // Flush css changes as explained in: https://stackoverflow.com/a/34726346
  // and more completely: https://stackoverflow.com/a/6956049
  function flushCss(element) {
    element.offsetHeight;
  }

  function addArrow(itemDom) {
    var MAIN_ITEM_HEIGHT = 24;
    var BOTTOM_PADDING = 20;
    var arrowDom = document.createElement('a');
    arrowDom.classList.add('arrow');
    arrowDom.innerHTML = '<img src="' + BASE_PATH + '/images/arrow.svg" />';
    arrowDom.onclick = function(itemDom) {
      return function () {
        // Calculated full height of the opened list
        var fullHeight = MAIN_ITEM_HEIGHT + BOTTOM_PADDING + itemDom.lastChild.clientHeight + 'px';

        itemDom.classList.toggle('open');

        if (itemDom.classList.contains('open')) {
          itemDom.style.height = fullHeight;
        } else {
          // If the list height is auto we have to set it to fullHeight
          // without tranistion before we shrink it to collapsed height
          if (itemDom.style.height === 'auto') {
            itemDom.style.transition = 'none';
            itemDom.style.height = fullHeight;
            flushCss(itemDom);
            itemDom.style.transition = '';
          }
          itemDom.style.height = MAIN_ITEM_HEIGHT + 'px';
        }

        return false;
      };
    }(itemDom);
    itemDom.appendChild(arrowDom);

    if ((item.current && item.children) || item.childCurrent) {
      itemDom.classList.add('open');
      itemDom.style.height = 'auto';
    } else {
      itemDom.style.height = MAIN_ITEM_HEIGHT + 'px';
    }
  }

  var menuDom = document.getElementById('docs-ul');
  for (var i = 0; i < menu.length; i++) {
    var item = menu[i];
    var itemDom = getEntry(item);

    if (item.childCurrent) {
      itemDom.classList.add('childCurrent');
    }

    if (item.children) {
      addArrow(itemDom);
      itemDom.classList.add('children');
      var children = document.createElement('ul');
      for (var j = 0; j < item.children.length; j++) {
        children.appendChild(getEntry(item.children[j]));
      }
      itemDom.appendChild(children);
    }
    menuDom.appendChild(itemDom);
  }
</script>
</div></main>
    <footer id="footer" aria-label="Footer">
  <div class="top">
    <a href="//www.cncf.io">
      <img
        class="cncf"
        src="/images/cncf.png"
        srcset="/images/cncf@2x.png 2x, /images/cncf@3x.png 3x" />
    </a>
    <p>We are a Cloud Native Computing Foundation graduated project.</p>
  </div>
  <div class="middle">
    <div class="grid-center">
      <div class="col_sm-12">
        <span>Getting Started</span>
        <a href="//github.com/rook/rook">GitHub</a>
        <a href="/docs/rook/v1.9/">Documentation</a>
        <a href="//github.com/rook/rook/blob/master/CONTRIBUTING.md#how-to-contribute">How to Contribute</a>
      </div>
      <div class="col_sm-12">
        <span>Community</span>
        <a href="//slack.rook.io/">Slack</a>
        <a href="//twitter.com/rook_io">Twitter</a>
        <a href="//groups.google.com/forum/#!forum/rook-dev">Forum</a>
        <a href="//blog.rook.io/">Blog</a>
      </div>
      <div class="col_sm-12">
        <span>Contact</span>
        <a href="mailto:cncf-rook-info@lists.cncf.io">Email</a>
        <a href="//github.com/rook/rook/issues">Feature request</a>
      </div>
      <div class="col_sm-12">
        <span>Top Contributors</span>
        <a href="//cloudical.io/">Cloudical</a>
        <a href="//cybozu.com">Cybozu, Inc</a>
        <a href="//www.redhat.com">Red Hat</a>
        <a href="//www.suse.com/">SUSE</a>
        <a href="//upbound.io">Upbound</a>
      </div>
    </div>
  </div>
  <div class="bottom">
    <div class="grid-center">
      <div class="col-8">
        <a class="logo" href="/">
          <img src="/images/rook-logo-small.svg" alt="rook.io" />
        </a>
        <p>
          &#169; Rook Authors 2022. Documentation distributed under
          <a href="https://creativecommons.org/licenses/by/4.0">CC-BY-4.0</a>.
        </p>
        <p>
          &#169; 2022 The Linux Foundation. All rights reserved. The Linux Foundation has
          registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our
          <a href="https://www.linuxfoundation.org/trademark-usage/">Trademark Usage</a> page.
        </p>
      </div>
    </div>
  </div>
</footer>


  <script src="/js/anchor.js"></script>
  <script>
    anchors.options = {
      placement: 'right',
      icon: '#',
    }

    document.addEventListener('DOMContentLoaded', function(event) {
      anchors.add('.docs-text h1, .docs-text h2, .docs-text h3, .docs-text h4, .docs-text h5, .docs-text h6');
    });
  </script>




    
  </body>
</html>
