












































<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="ie=edge" />

    
    <meta name="robots" content="noindex">
    

    <title>Ceph Docs</title>

    <link rel="canonical" href="https://rook.io/docs/rook/v1.1/ceph-block.html">

    <link rel="icon" href="/favicon.ico" />
<link rel="icon" type="image/png" href="/images/favicon_16x16.png" sizes="16x16" />
<link rel="icon" type="image/png" href="/images/favicon_32x32.png" sizes="32x32" />
<link rel="icon" type="image/png" href="/images/favicon_48x48.png" sizes="48x48" />
<link rel="icon" type="image/png" href="/images/favicon_192x192.png" sizes="192x192" />


    <link href="//fonts.googleapis.com/css?family=Montserrat:500|Open+Sans:300,400,600" rel="stylesheet">
    
    <link rel="stylesheet" href="/css/main.css">
    
      <link rel="stylesheet" href="/css/docs.css" />
    
  </head>
  <body>
    <nav id="navigation" aria-label="Navigation">
  <div>
    <div class="logo">
      <a href="/"><img src="/images/rook-logo.svg"/></a>
    </div>
    <div
      class="hamburger-controls"
      onclick="if (document.body.classList.contains('menu-open')) { document.body.classList.remove('menu-open') } else { document.body.classList.add('menu-open') }; return false;">
      <span></span> <span></span> <span></span>
    </div>
    <ul class="links">
      <li class="dropdown">
        <a role="button" href="javascript:void(0)">Documentation</a>
        <div class="dropdown-content">
          <a href="/docs/rook/v1.9/">Ceph</a>
          <a href="/docs/cassandra/v1.7/">Cassandra</a>
          <a href="/docs/nfs/v1.7/">NFS</a>
        </div>
      <li class="dropdown">
        <a role="button" href="javascript:void(0)">Community</a>
        <div class="dropdown-content">
          <a href="//github.com/rook/rook">GitHub</a>
          <a href="//slack.rook.io/">Slack</a>
          <a href="//groups.google.com/forum/#!forum/rook-dev">Forum</a>
          <a href="//twitter.com/rook_io">Twitter</a>
        </div>
      </li>
      <li><a href="//blog.rook.io/">Blog</a></li>
      <li><a class="button small" href="/docs/rook/v1.9/quickstart.html">Get Started</a></li>
    </ul>
  </div>
</nav>

    <main id="content" aria-label="Content"><div>



















<section class="docs-header">
  <h1>Ceph</h1>
  <div class="versions">
    <a role="button" href="javascript:void(0)">Rook Ceph v1.1</a>
    <div class="versions-dropdown-content">
      
        <a href="/docs/rook/v1.9/ceph-block.html">Rook Ceph v1.9</a>
      
        <a href="/docs/rook/v1.8/ceph-block.html">Rook Ceph v1.8</a>
      
        <a href="/docs/rook/v1.7/ceph-block.html">Rook Ceph v1.7</a>
      
        <a href="/docs/rook/v1.6/ceph-block.html">Rook Ceph v1.6</a>
      
        <a href="/docs/rook/v1.5/ceph-block.html">Rook Ceph v1.5</a>
      
        <a href="/docs/rook/v1.4/ceph-block.html">Rook Ceph v1.4</a>
      
        <a href="/docs/rook/v1.3/ceph-block.html">Rook Ceph v1.3</a>
      
        <a href="/docs/rook/v1.2/ceph-block.html">Rook Ceph v1.2</a>
      
        <a href="/docs/rook/v1.1/ceph-block.html" class="active">Rook Ceph v1.1</a>
      
        <a href="/docs/rook/v1.0/ceph-block.html">Rook Ceph v1.0</a>
      
        <a href="/docs/rook/v0.9/ceph-block.html">Rook Ceph v0.9</a>
      
        <a href="/docs/rook/v0.8/ceph-block.html">Rook Ceph v0.8</a>
      
        <a href="/docs/rook/v0.7/ceph-block.html">Rook Ceph v0.7</a>
      
        <a href="/docs/rook/v0.6/ceph-block.html">Rook Ceph v0.6</a>
      
        <a href="/docs/rook/v0.5/ceph-block.html">Rook Ceph v0.5</a>
      
        <a href="/docs/rook/latest/ceph-block.html">Rook Ceph latest</a>
      
    </div>
    <img src="/images/arrow.svg" />
  </div>
</section>
<div class="page">
  <div class="docs-menu">
      <ul id="docs-ul"></ul>
  </div>
  <div class="docs-content">
    <div class="docs-actions">
      <a id="edit" href="https://github.com/rook/rook/blob/master/Documentation/ceph-block.md">Edit on GitHub</a>
    </div>
    
      <div class="alert old">
        <p><b>PLEASE NOTE</b>: This document applies to v1.1 version and not to the latest <strong>stable</strong> release v1.9</p>
      </div>
    
    <div class="docs-text">
      
<h1 id="block-storage">Block Storage</h1>

<p>Block storage allows a single pod to mount storage. This guide shows how to create a simple, multi-tier web application on Kubernetes using persistent volumes enabled by Rook.</p>

<h2 id="prerequisites">Prerequisites</h2>

<p>This guide assumes a Rook cluster as explained in the <a href="/docs/rook/v1.1/ceph-quickstart.html">Quickstart</a>.</p>

<h2 id="provision-storage">Provision Storage</h2>

<p>Before Rook can provision storage, a <a href="https://kubernetes.io/docs/concepts/storage/storage-classes"><code class="language-plaintext highlighter-rouge">StorageClass</code></a> and <a href="/docs/rook/v1.1/ceph-pool-crd.html"><code class="language-plaintext highlighter-rouge">CephBlockPool</code></a> need to be created. This will allow Kubernetes to interoperate with Rook when provisioning persistent volumes.</p>

<p><strong>NOTE:</strong> This sample requires <em>at least 1 OSD per node</em>, with each OSD located on <em>3 different nodes</em>.</p>

<p>Each OSD must be located on a different node, because the <a href="/docs/rook/v1.1/ceph-pool-crd.html#spec"><code class="language-plaintext highlighter-rouge">failureDomain</code></a> is set to <code class="language-plaintext highlighter-rouge">host</code> and the <code class="language-plaintext highlighter-rouge">replicated.size</code> is set to <code class="language-plaintext highlighter-rouge">3</code>.</p>

<p><strong>NOTE</strong> This example uses the CSI driver, which is the preferred driver going forward for K8s 1.13 and newer. Examples are found in the <a href="https://github.com/rook/rook/tree/release-1.1/cluster/examples/kubernetes/ceph/csi/rbd">CSI RBD</a> directory. For an example of a storage class using the flex driver (required for K8s 1.12 or earlier), see the <a href="#flex-driver">Flex Driver</a> section below, which has examples in the <a href="https://github.com/rook/rook/tree/release-1.1/cluster/examples/kubernetes/ceph/flex">flex</a> directory.</p>

<p>Save this <code class="language-plaintext highlighter-rouge">StorageClass</code> definition as <code class="language-plaintext highlighter-rouge">storageclass.yaml</code>:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">ceph.rook.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">CephBlockPool</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">replicapool</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">rook-ceph</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">failureDomain</span><span class="pi">:</span> <span class="s">host</span>
  <span class="na">replicated</span><span class="pi">:</span>
    <span class="na">size</span><span class="pi">:</span> <span class="m">3</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">storage.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">StorageClass</span>
<span class="na">metadata</span><span class="pi">:</span>
   <span class="na">name</span><span class="pi">:</span> <span class="s">rook-ceph-block</span>
<span class="c1"># Change "rook-ceph" provisioner prefix to match the operator namespace if needed</span>
<span class="na">provisioner</span><span class="pi">:</span> <span class="s">rook-ceph.rbd.csi.ceph.com</span>
<span class="na">parameters</span><span class="pi">:</span>
    <span class="c1"># clusterID is the namespace where the rook cluster is running</span>
    <span class="na">clusterID</span><span class="pi">:</span> <span class="s">rook-ceph</span>
    <span class="c1"># Ceph pool into which the RBD image shall be created</span>
    <span class="na">pool</span><span class="pi">:</span> <span class="s">replicapool</span>

    <span class="c1"># RBD image format. Defaults to "2".</span>
    <span class="na">imageFormat</span><span class="pi">:</span> <span class="s2">"</span><span class="s">2"</span>

    <span class="c1"># RBD image features. Available for imageFormat: "2". CSI RBD currently supports only `layering` feature.</span>
    <span class="na">imageFeatures</span><span class="pi">:</span> <span class="s">layering</span>

    <span class="c1"># The secrets contain Ceph admin credentials.</span>
    <span class="s">csi.storage.k8s.io/provisioner-secret-name</span><span class="pi">:</span> <span class="s">rook-csi-rbd-provisioner</span>
    <span class="s">csi.storage.k8s.io/provisioner-secret-namespace</span><span class="pi">:</span> <span class="s">rook-ceph</span>
    <span class="s">csi.storage.k8s.io/node-stage-secret-name</span><span class="pi">:</span> <span class="s">rook-csi-rbd-node</span>
    <span class="s">csi.storage.k8s.io/node-stage-secret-namespace</span><span class="pi">:</span> <span class="s">rook-ceph</span>

    <span class="c1"># Specify the filesystem type of the volume. If not specified, csi-provisioner</span>
    <span class="c1"># will set default as `ext4`.</span>
    <span class="s">csi.storage.k8s.io/fstype</span><span class="pi">:</span> <span class="s">xfs</span>

<span class="c1"># Delete the rbd volume when a PVC is deleted</span>
<span class="na">reclaimPolicy</span><span class="pi">:</span> <span class="s">Delete</span>
</code></pre></div></div>

<p>If you’ve deployed the Rook operator in a namespace other than “rook-ceph”
as is common change the prefix in the provisioner to match the namespace
you used. For example, if the Rook operator is running in “rook-op” the
provisioner value should be “rook-op.rbd.csi.ceph.com”.</p>

<p>Create the storage class.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl create <span class="nt">-f</span> cluster/examples/kubernetes/ceph/csi/rbd/storageclass.yaml
</code></pre></div></div>

<p><strong>NOTE</strong> As <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#retain">specified by Kubernetes</a>, when using the <code class="language-plaintext highlighter-rouge">Retain</code> reclaim policy, any Ceph RBD image that is backed by a <code class="language-plaintext highlighter-rouge">PersistentVolume</code> will continue to exist even after the <code class="language-plaintext highlighter-rouge">PersistentVolume</code> has been deleted. These Ceph RBD images will need to be cleaned up manually using <code class="language-plaintext highlighter-rouge">rbd rm</code>.</p>

<h2 id="consume-the-storage-wordpress-sample">Consume the storage: Wordpress sample</h2>

<p>We create a sample app to consume the block storage provisioned by Rook with the classic wordpress and mysql apps.
Both of these apps will make use of block volumes provisioned by Rook.</p>

<p>Start mysql and wordpress from the <code class="language-plaintext highlighter-rouge">cluster/examples/kubernetes</code> folder:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl create <span class="nt">-f</span> mysql.yaml
kubectl create <span class="nt">-f</span> wordpress.yaml
</code></pre></div></div>

<p>Both of these apps create a block volume and mount it to their respective pod. You can see the Kubernetes volume claims by running the following:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get pvc
NAME             STATUS    VOLUME                                     CAPACITY   ACCESSMODES   AGE
mysql-pv-claim   Bound     pvc-95402dbc-efc0-11e6-bc9a-0cc47a3459ee   20Gi       RWO           1m
wp-pv-claim      Bound     pvc-39e43169-efc1-11e6-bc9a-0cc47a3459ee   20Gi       RWO           1m
</code></pre></div></div>

<p>Once the wordpress and mysql pods are in the <code class="language-plaintext highlighter-rouge">Running</code> state, get the cluster IP of the wordpress app and enter it in your browser:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get svc wordpress
NAME        CLUSTER-IP   EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>        AGE
wordpress   10.3.0.155   &lt;pending&gt;     80:30841/TCP   2m
</code></pre></div></div>

<p>You should see the wordpress app running.</p>

<p>If you are using Minikube, the Wordpress URL can be retrieved with this one-line command:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">echo http://$</span><span class="o">(</span>minikube ip<span class="o">)</span>:<span class="si">$(</span>kubectl get service wordpress <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.spec.ports[0].nodePort}'</span><span class="si">)</span>
</code></pre></div></div>

<p><strong>NOTE:</strong> When running in a vagrant environment, there will be no external IP address to reach wordpress with.  You will only be able to reach wordpress via the <code class="language-plaintext highlighter-rouge">CLUSTER-IP</code> from inside the Kubernetes cluster.</p>

<h2 id="consume-the-storage-toolbox">Consume the storage: Toolbox</h2>

<p>With the pool that was created above, we can also create a block image and mount it directly in a pod. See the <a href="/docs/rook/v1.1/direct-tools.html#block-storage-tools">Direct Block Tools</a> topic for more details.</p>

<h2 id="teardown">Teardown</h2>

<p>To clean up all the artifacts created by the block demo:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl delete -f wordpress.yaml
kubectl delete -f mysql.yaml
kubectl delete -n rook-ceph cephblockpools.ceph.rook.io replicapool
kubectl delete storageclass rook-ceph-block
</code></pre></div></div>

<h2 id="flex-driver">Flex Driver</h2>

<p>To create a volume based on the flex driver instead of the CSI driver, see the following example of a storage class.
Make sure the flex driver is enabled over Ceph CSI.
For this, you need to set <code class="language-plaintext highlighter-rouge">ROOK_ENABLE_FLEX_DRIVER</code> to <code class="language-plaintext highlighter-rouge">true</code> in your operator deployment in the <code class="language-plaintext highlighter-rouge">operator.yaml</code> file.
The pool definition is the same as for the CSI driver.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">ceph.rook.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">CephBlockPool</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">replicapool</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">rook-ceph</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">failureDomain</span><span class="pi">:</span> <span class="s">host</span>
  <span class="na">replicated</span><span class="pi">:</span>
    <span class="na">size</span><span class="pi">:</span> <span class="m">3</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">storage.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">StorageClass</span>
<span class="na">metadata</span><span class="pi">:</span>
   <span class="na">name</span><span class="pi">:</span> <span class="s">rook-ceph-block</span>
<span class="na">provisioner</span><span class="pi">:</span> <span class="s">ceph.rook.io/block</span>
<span class="na">parameters</span><span class="pi">:</span>
  <span class="na">blockPool</span><span class="pi">:</span> <span class="s">replicapool</span>
  <span class="c1"># The value of "clusterNamespace" MUST be the same as the one in which your rook cluster exist</span>
  <span class="na">clusterNamespace</span><span class="pi">:</span> <span class="s">rook-ceph</span>
  <span class="c1"># Specify the filesystem type of the volume. If not specified, it will use `ext4`.</span>
  <span class="na">fstype</span><span class="pi">:</span> <span class="s">xfs</span>
<span class="c1"># Optional, default reclaimPolicy is "Delete". Other options are: "Retain", "Recycle" as documented in https://kubernetes.io/docs/concepts/storage/storage-classes/</span>
<span class="na">reclaimPolicy</span><span class="pi">:</span> <span class="s">Retain</span>
<span class="c1"># Optional, if you want to add dynamic resize for PVC. Works for Kubernetes 1.14+</span>
<span class="c1"># For now only ext3, ext4, xfs resize support provided, like in Kubernetes itself.</span>
<span class="na">allowVolumeExpansion</span><span class="pi">:</span> <span class="no">true</span>
</code></pre></div></div>

<p>Create the pool and storage class.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl create <span class="nt">-f</span> cluster/examples/kubernetes/ceph/flex/storageclass.yaml
</code></pre></div></div>

<p>Continue with the example above for the <a href="#consume-the-storage-wordpress-sample">wordpress application</a>.</p>

<h2 id="advanced-example-erasure-coded-block-storage">Advanced Example: Erasure Coded Block Storage</h2>

<p><strong>IMPORTANT:</strong> This is only possible when using the Flex driver. Ceph CSI 1.2 (with Rook 1.1) does not support this type of configuration yet.</p>

<p>If you want to use erasure coded pool with RBD, your OSDs must use <code class="language-plaintext highlighter-rouge">bluestore</code> as their <code class="language-plaintext highlighter-rouge">storeType</code>.
Additionally the nodes that are going to mount the erasure coded RBD block storage must have Linux kernel &gt;= <code class="language-plaintext highlighter-rouge">4.11</code>.</p>

<p>To be able to use an erasure coded pool you need to create two pools (as seen below in the definitions): one erasure coded and one replicated.
The replicated pool must be specified as the <code class="language-plaintext highlighter-rouge">blockPool</code> parameter. It is used for the metadata of the RBD images.
The erasure coded pool must be set as the <code class="language-plaintext highlighter-rouge">dataBlockPool</code> parameter below. It is used for the data of the RBD images.</p>

<p><strong>NOTE:</strong> This example requires <em>at least 3 bluestore OSDs</em>, with each OSD located on a <em>different node</em>.</p>

<p>The OSDs must be located on different nodes, because the <a href="/docs/rook/v1.1/ceph-pool-crd.html#spec"><code class="language-plaintext highlighter-rouge">failureDomain</code></a> is set to <code class="language-plaintext highlighter-rouge">host</code> and the <code class="language-plaintext highlighter-rouge">erasureCoded</code> chunk settings require at least 3 different OSDs (2 <code class="language-plaintext highlighter-rouge">dataChunks</code> + 1 <code class="language-plaintext highlighter-rouge">codingChunks</code>).</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">ceph.rook.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">CephBlockPool</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">replicated-metadata-pool</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">rook-ceph</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">failureDomain</span><span class="pi">:</span> <span class="s">host</span>
  <span class="na">replicated</span><span class="pi">:</span>
    <span class="na">size</span><span class="pi">:</span> <span class="m">3</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">ceph.rook.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">CephBlockPool</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">ec-data-pool</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">rook-ceph</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">failureDomain</span><span class="pi">:</span> <span class="s">host</span>
  <span class="c1"># Make sure you have enough nodes and OSDs running bluestore to support the replica size or erasure code chunks.</span>
  <span class="c1"># For the below settings, you need at least 3 OSDs on different nodes (because the `failureDomain` is `host` by default).</span>
  <span class="na">erasureCoded</span><span class="pi">:</span>
    <span class="na">dataChunks</span><span class="pi">:</span> <span class="m">2</span>
    <span class="na">codingChunks</span><span class="pi">:</span> <span class="m">1</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">storage.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">StorageClass</span>
<span class="na">metadata</span><span class="pi">:</span>
   <span class="na">name</span><span class="pi">:</span> <span class="s">rook-ceph-block</span>
<span class="na">provisioner</span><span class="pi">:</span> <span class="s">ceph.rook.io/block</span>
<span class="na">parameters</span><span class="pi">:</span>
  <span class="na">blockPool</span><span class="pi">:</span> <span class="s">replicated-metadata-pool</span>
  <span class="na">dataBlockPool</span><span class="pi">:</span> <span class="s">ec-data-pool</span>
  <span class="c1"># Specify the namespace of the rook cluster from which to create volumes.</span>
  <span class="c1"># If not specified, it will use `rook` as the default namespace of the cluster.</span>
  <span class="c1"># This is also the namespace where the cluster will be</span>
  <span class="na">clusterNamespace</span><span class="pi">:</span> <span class="s">rook-ceph</span>
  <span class="c1"># Specify the filesystem type of the volume. If not specified, it will use `ext4`.</span>
  <span class="na">fstype</span><span class="pi">:</span> <span class="s">xfs</span>
<span class="c1"># Works for Kubernetes 1.14+</span>
<span class="na">allowVolumeExpansion</span><span class="pi">:</span> <span class="no">true</span>
</code></pre></div></div>

<p>(These definitions can also be found in the <a href="https://github.com/rook/rook/blob/release-1.1/cluster/examples/kubernetes/ceph/flex/storage-class-ec.yaml"><code class="language-plaintext highlighter-rouge">storageclass-ec.yaml</code></a> file)</p>

    </div>
  </div>
</div>

<script>
  var menu = [];
  var BASE_PATH = "";

  function add(name, url, isChild, current) {
    var item = { name: name, url: url, current: current };
    var container = menu;
    if (isChild && menu.length > 0) {
      menu[menu.length-1].children = menu[menu.length-1].children || [];
      container = menu[menu.length-1].children;
      if (current) {
        menu[menu.length-1].childCurrent = true;
      }
    }
    container.push(item);
  }

  
    add(
      "Rook",
      "/docs/rook/v1.1/",
      false,
      false
    );
  
    add(
      "Quickstart",
      "/docs/rook/v1.1/quickstart-toc.html",
      false,
      false
    );
  
    add(
      "Cassandra",
      "/docs/rook/v1.1/cassandra.html",
      true,
      false
    );
  
    add(
      "Ceph Storage",
      "/docs/rook/v1.1/ceph-quickstart.html",
      true,
      false
    );
  
    add(
      "CockroachDB",
      "/docs/rook/v1.1/cockroachdb.html",
      true,
      false
    );
  
    add(
      "EdgeFS Geo-Transparent Storage",
      "/docs/rook/v1.1/edgefs-quickstart.html",
      true,
      false
    );
  
    add(
      "Minio Object Store",
      "/docs/rook/v1.1/minio-object-store.html",
      true,
      false
    );
  
    add(
      "Network File System (NFS)",
      "/docs/rook/v1.1/nfs.html",
      true,
      false
    );
  
    add(
      "YugabyteDB",
      "/docs/rook/v1.1/yugabytedb.html",
      true,
      false
    );
  
    add(
      "Prerequisites",
      "/docs/rook/v1.1/k8s-pre-reqs.html",
      false,
      false
    );
  
    add(
      "FlexVolume Configuration",
      "/docs/rook/v1.1/flexvolume.html",
      true,
      false
    );
  
    add(
      "Pod Security Policies",
      "/docs/rook/v1.1/psp.html",
      true,
      false
    );
  
    add(
      "Tectonic Bare Metal",
      "/docs/rook/v1.1/tectonic.html",
      true,
      false
    );
  
    add(
      "OpenShift",
      "/docs/rook/v1.1/openshift.html",
      true,
      false
    );
  
    add(
      "Ceph Storage",
      "/docs/rook/v1.1/ceph-storage.html",
      false,
      false
    );
  
    add(
      "Examples",
      "/docs/rook/v1.1/ceph-examples.html",
      true,
      false
    );
  
    add(
      "Block Storage",
      "/docs/rook/v1.1/ceph-block.html",
      true,
      true
    );
  
    add(
      "Object Storage",
      "/docs/rook/v1.1/ceph-object.html",
      true,
      false
    );
  
    add(
      "Shared File System",
      "/docs/rook/v1.1/ceph-filesystem.html",
      true,
      false
    );
  
    add(
      "Dashboard",
      "/docs/rook/v1.1/ceph-dashboard.html",
      true,
      false
    );
  
    add(
      "Monitoring",
      "/docs/rook/v1.1/ceph-monitoring.html",
      true,
      false
    );
  
    add(
      "Cluster CRD",
      "/docs/rook/v1.1/ceph-cluster-crd.html",
      true,
      false
    );
  
    add(
      "Block Pool CRD",
      "/docs/rook/v1.1/ceph-pool-crd.html",
      true,
      false
    );
  
    add(
      "Object Store CRD",
      "/docs/rook/v1.1/ceph-object-store-crd.html",
      true,
      false
    );
  
    add(
      "Object Bucket Claim",
      "/docs/rook/v1.1/ceph-object-bucket-claim.html",
      true,
      false
    );
  
    add(
      "Object Store User CRD",
      "/docs/rook/v1.1/ceph-object-store-user-crd.html",
      true,
      false
    );
  
    add(
      "Shared File System CRD",
      "/docs/rook/v1.1/ceph-filesystem-crd.html",
      true,
      false
    );
  
    add(
      "NFS CRD",
      "/docs/rook/v1.1/ceph-nfs-crd.html",
      true,
      false
    );
  
    add(
      "Ceph CSI",
      "/docs/rook/v1.1/ceph-csi-drivers.html",
      true,
      false
    );
  
    add(
      "Configuration",
      "/docs/rook/v1.1/ceph-configuration.html",
      true,
      false
    );
  
    add(
      "Upgrades",
      "/docs/rook/v1.1/ceph-upgrade.html",
      true,
      false
    );
  
    add(
      "Cleanup",
      "/docs/rook/v1.1/ceph-teardown.html",
      true,
      false
    );
  
    add(
      "EdgeFS Storage",
      "/docs/rook/v1.1/edgefs-storage.html",
      false,
      false
    );
  
    add(
      "Cluster CRD",
      "/docs/rook/v1.1/edgefs-cluster-crd.html",
      true,
      false
    );
  
    add(
      "ISGW Link CRD",
      "/docs/rook/v1.1/edgefs-isgw-crd.html",
      true,
      false
    );
  
    add(
      "Scale-Out NFS CRD",
      "/docs/rook/v1.1/edgefs-nfs-crd.html",
      true,
      false
    );
  
    add(
      "Edge-X S3 CRD",
      "/docs/rook/v1.1/edgefs-s3x-crd.html",
      true,
      false
    );
  
    add(
      "AWS S3 CRD",
      "/docs/rook/v1.1/edgefs-s3-crd.html",
      true,
      false
    );
  
    add(
      "OpenStack/SWIFT CRD",
      "/docs/rook/v1.1/edgefs-swift-crd.html",
      true,
      false
    );
  
    add(
      "iSCSI Target CRD",
      "/docs/rook/v1.1/edgefs-iscsi-crd.html",
      true,
      false
    );
  
    add(
      "CSI driver",
      "/docs/rook/v1.1/edgefs-csi.html",
      true,
      false
    );
  
    add(
      "Monitoring",
      "/docs/rook/v1.1/edgefs-monitoring.html",
      true,
      false
    );
  
    add(
      "User Interface",
      "/docs/rook/v1.1/edgefs-ui.html",
      true,
      false
    );
  
    add(
      "VDEV Management",
      "/docs/rook/v1.1/edgefs-vdev-management.html",
      true,
      false
    );
  
    add(
      "Upgrade",
      "/docs/rook/v1.1/edgefs-upgrade.html",
      true,
      false
    );
  
    add(
      "Cassandra Cluster CRD",
      "/docs/rook/v1.1/cassandra-cluster-crd.html",
      false,
      false
    );
  
    add(
      "Upgrade",
      "/docs/rook/v1.1/cassandra-operator-upgrade.html",
      true,
      false
    );
  
    add(
      "CockroachDB Cluster CRD",
      "/docs/rook/v1.1/cockroachdb-cluster-crd.html",
      false,
      false
    );
  
    add(
      "Minio Object Store CRD",
      "/docs/rook/v1.1/minio-object-store-crd.html",
      false,
      false
    );
  
    add(
      "NFS Server CRD",
      "/docs/rook/v1.1/nfs-crd.html",
      false,
      false
    );
  
    add(
      "YugabyteDB Cluster CRD",
      "/docs/rook/v1.1/yugabytedb-cluster-crd.html",
      false,
      false
    );
  
    add(
      "Helm Charts",
      "/docs/rook/v1.1/helm.html",
      false,
      false
    );
  
    add(
      "Ceph Operator",
      "/docs/rook/v1.1/helm-operator.html",
      true,
      false
    );
  
    add(
      "Common Issues",
      "/docs/rook/v1.1/common-issues.html",
      false,
      false
    );
  
    add(
      "Ceph Common Issues",
      "/docs/rook/v1.1/ceph-common-issues.html",
      true,
      false
    );
  
    add(
      "Ceph Tools",
      "/docs/rook/v1.1/ceph-tools.html",
      false,
      false
    );
  
    add(
      "Toolbox",
      "/docs/rook/v1.1/ceph-toolbox.html",
      true,
      false
    );
  
    add(
      "Direct Tools",
      "/docs/rook/v1.1/direct-tools.html",
      true,
      false
    );
  
    add(
      "Advanced Configuration",
      "/docs/rook/v1.1/ceph-advanced-configuration.html",
      true,
      false
    );
  
    add(
      "Container Linux",
      "/docs/rook/v1.1/container-linux.html",
      true,
      false
    );
  
    add(
      "Disaster Recovery",
      "/docs/rook/v1.1/disaster-recovery.html",
      true,
      false
    );
  
    add(
      "Contributing",
      "/docs/rook/v1.1/development-flow.html",
      false,
      false
    );
  
    add(
      "Multi-Node Test Environment",
      "/docs/rook/v1.1/development-environment.html",
      true,
      false
    );
  

  function getEntry(item) {
    var itemDom = document.createElement('li');

    if (item.current) {
      itemDom.innerHTML = item.name;
      itemDom.classList.add('current');
    } else {
      itemDom.innerHTML = '<a href="' + item.url + '">' + item.name + '</a>';
    }

    return itemDom;
  }

  // Flush css changes as explained in: https://stackoverflow.com/a/34726346
  // and more completely: https://stackoverflow.com/a/6956049
  function flushCss(element) {
    element.offsetHeight;
  }

  function addArrow(itemDom) {
    var MAIN_ITEM_HEIGHT = 24;
    var BOTTOM_PADDING = 20;
    var arrowDom = document.createElement('a');
    arrowDom.classList.add('arrow');
    arrowDom.innerHTML = '<img src="' + BASE_PATH + '/images/arrow.svg" />';
    arrowDom.onclick = function(itemDom) {
      return function () {
        // Calculated full height of the opened list
        var fullHeight = MAIN_ITEM_HEIGHT + BOTTOM_PADDING + itemDom.lastChild.clientHeight + 'px';

        itemDom.classList.toggle('open');

        if (itemDom.classList.contains('open')) {
          itemDom.style.height = fullHeight;
        } else {
          // If the list height is auto we have to set it to fullHeight
          // without tranistion before we shrink it to collapsed height
          if (itemDom.style.height === 'auto') {
            itemDom.style.transition = 'none';
            itemDom.style.height = fullHeight;
            flushCss(itemDom);
            itemDom.style.transition = '';
          }
          itemDom.style.height = MAIN_ITEM_HEIGHT + 'px';
        }

        return false;
      };
    }(itemDom);
    itemDom.appendChild(arrowDom);

    if ((item.current && item.children) || item.childCurrent) {
      itemDom.classList.add('open');
      itemDom.style.height = 'auto';
    } else {
      itemDom.style.height = MAIN_ITEM_HEIGHT + 'px';
    }
  }

  var menuDom = document.getElementById('docs-ul');
  for (var i = 0; i < menu.length; i++) {
    var item = menu[i];
    var itemDom = getEntry(item);

    if (item.childCurrent) {
      itemDom.classList.add('childCurrent');
    }

    if (item.children) {
      addArrow(itemDom);
      itemDom.classList.add('children');
      var children = document.createElement('ul');
      for (var j = 0; j < item.children.length; j++) {
        children.appendChild(getEntry(item.children[j]));
      }
      itemDom.appendChild(children);
    }
    menuDom.appendChild(itemDom);
  }
</script>
</div></main>
    <footer id="footer" aria-label="Footer">
  <div class="top">
    <a href="//www.cncf.io">
      <img
        class="cncf"
        src="/images/cncf.png"
        srcset="/images/cncf@2x.png 2x, /images/cncf@3x.png 3x" />
    </a>
    <p>We are a Cloud Native Computing Foundation graduated project.</p>
  </div>
  <div class="middle">
    <div class="grid-center">
      <div class="col_sm-12">
        <span>Getting Started</span>
        <a href="//github.com/rook/rook">GitHub</a>
        <a href="/docs/rook/v1.9/">Documentation</a>
        <a href="//github.com/rook/rook/blob/master/CONTRIBUTING.md#how-to-contribute">How to Contribute</a>
      </div>
      <div class="col_sm-12">
        <span>Community</span>
        <a href="//slack.rook.io/">Slack</a>
        <a href="//twitter.com/rook_io">Twitter</a>
        <a href="//groups.google.com/forum/#!forum/rook-dev">Forum</a>
        <a href="//blog.rook.io/">Blog</a>
      </div>
      <div class="col_sm-12">
        <span>Contact</span>
        <a href="mailto:cncf-rook-info@lists.cncf.io">Email</a>
        <a href="//github.com/rook/rook/issues">Feature request</a>
      </div>
      <div class="col_sm-12">
        <span>Top Contributors</span>
        <a href="//cloudical.io/">Cloudical</a>
        <a href="//cybozu.com">Cybozu, Inc</a>
        <a href="//www.redhat.com">Red Hat</a>
        <a href="//www.suse.com/">SUSE</a>
        <a href="//upbound.io">Upbound</a>
      </div>
    </div>
  </div>
  <div class="bottom">
    <div class="grid-center">
      <div class="col-8">
        <a class="logo" href="/">
          <img src="/images/rook-logo-small.svg" alt="rook.io" />
        </a>
        <p>
          &#169; Rook Authors 2022. Documentation distributed under
          <a href="https://creativecommons.org/licenses/by/4.0">CC-BY-4.0</a>.
        </p>
        <p>
          &#169; 2022 The Linux Foundation. All rights reserved. The Linux Foundation has
          registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our
          <a href="https://www.linuxfoundation.org/trademark-usage/">Trademark Usage</a> page.
        </p>
      </div>
    </div>
  </div>
</footer>


  <script src="/js/anchor.js"></script>
  <script>
    anchors.options = {
      placement: 'right',
      icon: '#',
    }

    document.addEventListener('DOMContentLoaded', function(event) {
      anchors.add('.docs-text h1, .docs-text h2, .docs-text h3, .docs-text h4, .docs-text h5, .docs-text h6');
    });
  </script>




    
  </body>
</html>
